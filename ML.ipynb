{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f36a9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¯ Random Forest HPO Comparison (D=3) - í•™ìŠµ ëŠ¥ë ¥ ë³µì›\n",
      "   Parameters: (n_estimators, max_depth, max_features)\n",
      "   Start Point: (50, 15, 50)\n",
      "================================================================================\n",
      "Loading Fashion MNIST (Subsample for increased difficulty)...\n",
      "  [CHECK 1: Raw Data] X Shape: (70000, 784), Y Type: int64\n",
      "  [CHECK 1: Raw Data] X min/max: 0.0/255.0\n",
      "  [CHECK 4: Scaled Data] X_train mean/std: -0.0000 / 1.0000\n",
      "Data Loaded: Train=3500 samples, Validation=1500 samples.\n",
      "\n",
      "ğŸš€ 3D COMPRESSION climb start at (50, 15, 50), f=1.0000\n",
      "\n",
      "================================================================================\n",
      "ğŸ”„ Iteration 1/10\n",
      "================================================================================\n",
      "  ğŸ“ Climbed 0 steps, now at (50, 15, 50), f=1\n",
      "\n",
      "âš ï¸ STUCK at local minimum (50, 15, 50), f=1\n",
      "  ğŸ” Detecting basins along all 3 dimensions...\n",
      "    [Dim 0] (1D Detect @ x=50, f=1.0000) -> Basin: [30, 70] (len=41)\n",
      "    [Dim 1] (1D Detect @ x=15, f=1.0000) -> Basin: [-5, 35] (len=41)\n",
      "    [Dim 2] (1D Detect @ x=50, f=1.0000) -> Basin: [30, 70] (len=41)\n",
      "\n",
      "  âš ï¸ Restart candidates didn't improve fitness. Stopping.\n",
      "\n",
      "ğŸ FINAL 3D COMPRESSION RESULTS ğŸ\n",
      "  Final position: (50, 15, 50), Final fitness: 1, Total steps: 1\n",
      "\n",
      "ğŸš€ 3D BASELINE climb start at (50, 15, 50), f=1.0000\n",
      "\n",
      "ğŸ FINAL 3D BASELINE RESULTS ğŸ\n",
      "  Final position: (50, 15, 50), Final fitness: 1, Total steps: 1\n",
      "\n",
      "================================================================================\n",
      " Â  Â  Â  Â FINAL RANDOM FOREST HPO COMPARISON\n",
      "================================================================================\n",
      " Â Compression Hill Climbing     :\n",
      " Â  Â - Final Params (N, D): (50, 15, 50)             \n",
      " Â  Â - Final Fitness (Min): 1.000000                 \n",
      " Â  Â - Final Accuracy: Â  Â  Â 0.000000                 \n",
      " Â  Â - Total Steps: Â  Â  Â  Â  1                        \n",
      " Â  Â - Time Taken (s): Â  Â  Â 321.4550                 \n",
      " Â Baseline Hill Climbing        :\n",
      " Â  Â - Final Params (N, D): (50, 15, 50)             \n",
      " Â  Â - Final Fitness (Min): 1.000000                 \n",
      " Â  Â - Final Accuracy: Â  Â  Â 0.000000                 \n",
      " Â  Â - Total Steps: Â  Â  Â  Â  1                        \n",
      " Â  Â - Time Taken (s): Â  Â  Â 45.0790                  \n",
      "\n",
      "--- HPO Efficacy ---\n",
      "âš ï¸ Baseline and Compression HC performed similarly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_openml \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler # ìŠ¤ì¼€ì¼ëŸ¬ ì¶”ê°€\n",
    "from scipy.special import expit as sigmoid, logit\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import sys\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 0: CORE FRAMEWORK FUNCTIONS (Self-Contained)\n",
    "# (SigmoidWarping, CompressionManagerND, hill_climb_with_compression_nd, etc.)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Sigmoid Warping and Compression Metadata Classes ---\n",
    "# (Classes remain unchanged)\n",
    "\n",
    "class SigmoidWarping:\n",
    "    def __init__(self, node_index, length, steepness=5.0):\n",
    "        self.node_start = int(node_index)\n",
    "        self.length = int(length)\n",
    "        self.node_end = self.node_start + self.length\n",
    "        self.steepness = float(steepness)\n",
    "        self.shift = self.length - 1 \n",
    "\n",
    "    def forward(self, node):\n",
    "        node = np.atleast_1d(node).astype(float)\n",
    "        position = np.zeros(len(node), dtype=float)\n",
    "        for i, n in enumerate(node):\n",
    "            if n < self.node_start: position[i] = float(n)\n",
    "            elif n > self.node_end: position[i] = float(n) - self.shift\n",
    "            else:\n",
    "                if n == self.node_start: position[i] = float(self.node_start)\n",
    "                elif n == self.node_end: position[i] = float(self.node_start + 1)\n",
    "                else:\n",
    "                    t = (n - self.node_start) / self.length\n",
    "                    x = self.steepness * (t - 0.5)\n",
    "                    position[i] = self.node_start + sigmoid(x)\n",
    "        return position[0] if len(node) == 1 else position\n",
    "\n",
    "    def inverse(self, position):\n",
    "        position = np.atleast_1d(position).astype(float)\n",
    "        node = np.zeros(len(position), dtype=int)\n",
    "        for i, pos in enumerate(position):\n",
    "            if pos < self.node_start: node[i] = int(np.floor(pos))\n",
    "            elif pos >= self.node_start + 1.0: node[i] = int(np.ceil(pos + self.shift))\n",
    "            else:\n",
    "                s = np.clip(pos - self.node_start, 0.0, 1.0)\n",
    "                if s <= 0.01: node[i] = self.node_start\n",
    "                elif s >= 0.99: node[i] = self.node_end\n",
    "                else:\n",
    "                    x = logit(s)\n",
    "                    t = x / self.steepness + 0.5\n",
    "                    node_f = self.node_start + t * self.length\n",
    "                    node[i] = int(round(node_f))\n",
    "        return node[0] if len(node) == 1 else node\n",
    "\n",
    "class MetadataCompressionOriginalSpace:\n",
    "    def __init__(self, compressions_x_space=None, steepness=5.0):\n",
    "        self.metadata_x = sorted(compressions_x_space or [], key=lambda x: x[0])\n",
    "        self.steepness = float(steepness)\n",
    "        self.warpings = []\n",
    "        if self.metadata_x: self._build_warpings()\n",
    "\n",
    "    def _build_warpings(self):\n",
    "        cumulative_shift = 0\n",
    "        for i, (x_start, x_length) in enumerate(self.metadata_x):\n",
    "            z_start = x_start - cumulative_shift\n",
    "            z_length = x_length\n",
    "            warping = SigmoidWarping(z_start, z_length, self.steepness)\n",
    "            self.warpings.append(warping)\n",
    "            cumulative_shift += (z_length - 1)\n",
    "\n",
    "    def forward(self, node):\n",
    "        position = node\n",
    "        for warping in self.warpings: position = warping.forward(position)\n",
    "        return position\n",
    "\n",
    "    def inverse(self, position):\n",
    "        node = position\n",
    "        for warping in reversed(self.warpings): node = warping.inverse(node)\n",
    "        return node\n",
    "\n",
    "def detect_compression_basin(fitness_func, local_min_x, max_search=100):\n",
    "    local_min_fitness = fitness_func(local_min_x)\n",
    "    \n",
    "    # LEFT search logic...\n",
    "    left_boundary = local_min_x\n",
    "    farthest_left_equal = local_min_x\n",
    "    found_left_equal = False\n",
    "    found_left_exit = False\n",
    "    for i in range(1, max_search + 1):\n",
    "        current_x = local_min_x - i\n",
    "        current_fitness = fitness_func(current_x)\n",
    "        if abs(current_fitness - local_min_fitness) < 1e-9: farthest_left_equal = current_x; found_left_equal = True\n",
    "        elif current_fitness > local_min_fitness: pass\n",
    "        else: left_boundary = current_x + 1; found_left_exit = True; break\n",
    "    else: left_boundary = local_min_x - max_search\n",
    "    if not found_left_exit and found_left_equal: left_boundary = farthest_left_equal\n",
    "\n",
    "    # RIGHT search logic...\n",
    "    right_boundary = local_min_x\n",
    "    farthest_right_equal = local_min_x\n",
    "    found_right_equal = False\n",
    "    found_right_exit = False\n",
    "    for i in range(1, max_search + 1):\n",
    "        current_x = local_min_x + i\n",
    "        current_fitness = fitness_func(current_x)\n",
    "        if abs(current_fitness - local_min_fitness) < 1e-9: farthest_right_equal = current_x; found_right_equal = True\n",
    "        elif current_fitness > local_min_fitness: pass\n",
    "        else: right_boundary = current_x - 1; found_right_exit = True; break\n",
    "    else: right_boundary = local_min_x + max_search\n",
    "    if not found_right_exit and found_right_equal: right_boundary = farthest_right_equal\n",
    "\n",
    "    basin_length = right_boundary - left_boundary + 1\n",
    "    if basin_length < 2: return None\n",
    "    if not (found_left_equal or found_right_equal or found_left_exit or found_right_exit): return None\n",
    "    return (left_boundary, basin_length)\n",
    "\n",
    "def merge_overlapping_compressions(compressions):\n",
    "    if not compressions: return []\n",
    "    sorted_comps = sorted(compressions, key=lambda x: x[0])\n",
    "    merged = []\n",
    "    for start, length in sorted_comps:\n",
    "        end = start + length - 1\n",
    "        if not merged: merged.append((start, length)); continue\n",
    "        last_start, last_length = merged[-1]\n",
    "        last_end = last_start + last_length - 1\n",
    "        if start <= last_end + 1:\n",
    "            new_start = min(start, last_start)\n",
    "            new_end = max(end, last_end)\n",
    "            new_length = new_end - new_start + 1\n",
    "            merged[-1] = (new_start, new_length)\n",
    "        else: merged.append((start, length))\n",
    "    return merged\n",
    "\n",
    "class CompressionManagerND:\n",
    "    def __init__(self, dim, steepness=5.0):\n",
    "        self.dim = dim\n",
    "        self.steepness = float(steepness)\n",
    "        self.dim_compressions = [{} for _ in range(dim)]\n",
    "        self.dim_systems = [{} for _ in range(dim)]\n",
    "    \n",
    "    def update_dimension(self, vary_dim, fixed_coords, basin):\n",
    "        if basin is None: return\n",
    "        comps = self.dim_compressions[vary_dim].get(fixed_coords, [])\n",
    "        comps.append(basin)\n",
    "        comps = merge_overlapping_compressions(comps)\n",
    "        self.dim_compressions[vary_dim][fixed_coords] = comps\n",
    "        self.dim_systems[vary_dim][fixed_coords] = MetadataCompressionOriginalSpace(comps, self.steepness)\n",
    "    \n",
    "    def get_system(self, vary_dim, fixed_coords):\n",
    "        return self.dim_systems[vary_dim].get(fixed_coords, None)\n",
    "\n",
    "def detect_basin_along_dimension(fitness_func_nd, point, vary_dim, max_search=100):\n",
    "    def f1d(val):\n",
    "        new_point = list(point)\n",
    "        new_point[vary_dim] = int(val)\n",
    "        return fitness_func_nd(tuple(new_point))\n",
    "    \n",
    "    basin = detect_compression_basin(f1d, local_min_x=int(point[vary_dim]), max_search=max_search)\n",
    "    \n",
    "    min_val = int(point[vary_dim])\n",
    "    min_f = fitness_func_nd(point)\n",
    "    \n",
    "    if basin:\n",
    "        start, length = basin\n",
    "        print(f\"    [Dim {vary_dim}] (1D Detect @ x={min_val}, f={min_f:.4f}) -> Basin: [{start}, {start+length-1}] (len={length})\")\n",
    "    else:\n",
    "        print(f\"    [Dim {vary_dim}] (1D Detect @ x={min_val}, f={min_f:.4f}) -> No compressible basin found.\")\n",
    "        \n",
    "    return basin\n",
    "\n",
    "def hill_climb_with_compression_nd(fitness_func_nd, start_point, dim, max_iterations=10, basin_max_search=100, global_min_threshold=1e-6):\n",
    "    traj = []\n",
    "    cm = CompressionManagerND(dim, steepness=5.0)\n",
    "    point = tuple(int(x) for x in start_point)\n",
    "    f = fitness_func_nd(point)\n",
    "    traj.append((point, f, False))\n",
    "    \n",
    "    print(f\"\\nğŸš€ {dim}D COMPRESSION climb start at {point}, f={f:.4f}\\n\")\n",
    "\n",
    "    for it in range(max_iterations):\n",
    "        print(f\"================================================================================\")\n",
    "        print(f\"ğŸ”„ Iteration {it+1}/{max_iterations}\")\n",
    "        print(f\"================================================================================\")\n",
    "        \n",
    "        step_count = 0\n",
    "        while True:\n",
    "            candidates = []\n",
    "            # 1. O(D) Axis-aligned Neighbors\n",
    "            for d in range(dim):\n",
    "                fixed_coords = tuple(point[i] for i in range(dim) if i != d)\n",
    "                comp_sys = cm.get_system(d, fixed_coords)\n",
    "                if comp_sys is not None:\n",
    "                    z = comp_sys.forward(point[d])\n",
    "                    nm, np_ = comp_sys.inverse(z - 1), comp_sys.inverse(z + 1)\n",
    "                else:\n",
    "                    nm, np_ = point[d] - 1, point[d] + 1\n",
    "                \n",
    "                pm = list(point); pm[d] = nm\n",
    "                pp = list(point); pp[d] = np_\n",
    "                candidates.append((tuple(pm), fitness_func_nd(tuple(pm))))\n",
    "                candidates.append((tuple(pp), fitness_func_nd(tuple(pp))))\n",
    "            \n",
    "            # 2. O(D^2) Diagonal Neighbors\n",
    "            for d1, d2 in itertools.combinations(range(dim), 2):\n",
    "                for o1 in [1, -1]:\n",
    "                    for o2 in [1, -1]:\n",
    "                        np_ = list(point); np_[d1] += o1; np_[d2] += o2\n",
    "                        candidates.append((tuple(np_), fitness_func_nd(tuple(np_))))\n",
    "            \n",
    "            best_point, best_f = point, f\n",
    "            for cp, cf in candidates:\n",
    "                if cf < best_f - 1e-9: best_point, best_f = cp, cf\n",
    "            \n",
    "            if best_f < f - 1e-9:\n",
    "                point, f = best_point, best_f\n",
    "                used_comp = any(cm.get_system(d, tuple(point[i] for i in range(dim) if i != d)) is not None for d in range(dim))\n",
    "                traj.append((point, f, used_comp))\n",
    "                step_count += 1\n",
    "            else:\n",
    "                print(f\"  ğŸ“ Climbed {step_count} steps, now at {point}, f={f:.6g}\")\n",
    "                break\n",
    "        \n",
    "        if abs(f) < global_min_threshold:\n",
    "            print(\"\\nğŸ‰ SUCCESS: reached near-global minimum\")\n",
    "            break\n",
    "        \n",
    "        # Basin Detection\n",
    "        print(f\"\\nâš ï¸ STUCK at local minimum {point}, f={f:.6g}\")\n",
    "        print(f\"  ğŸ” Detecting basins along all {dim} dimensions...\")\n",
    "        basins = {}\n",
    "        for d in range(dim):\n",
    "            basin = detect_basin_along_dimension(fitness_func_nd, point, d, max_search=basin_max_search)\n",
    "            if basin:\n",
    "                fixed_coords = tuple(point[i] for i in range(dim) if i != d)\n",
    "                cm.update_dimension(d, fixed_coords, basin)\n",
    "                basins[d] = basin\n",
    "        \n",
    "        # Restart Logic\n",
    "        restart_candidates = []\n",
    "        for d, (b_start, b_len) in basins.items():\n",
    "            b_end = b_start + b_len - 1\n",
    "            rp1 = list(point); rp1[d] = b_start - 1\n",
    "            rp2 = list(point); rp2[d] = b_end + 1\n",
    "            restart_candidates.append((tuple(rp1), fitness_func_nd(tuple(rp1))))\n",
    "            restart_candidates.append((tuple(rp2), fitness_func_nd(tuple(rp2))))\n",
    "        \n",
    "        if restart_candidates:\n",
    "            best_r_p, best_r_f = min(restart_candidates, key=lambda t: t[1])\n",
    "            if best_r_f < f - 1e-9:\n",
    "                print(f\"  â¡ï¸ Restarting from {best_r_p}, f={best_r_f:.4f}\")\n",
    "                point, f = best_r_p, best_r_f\n",
    "                traj.append((point, f, True))\n",
    "            else:\n",
    "                print(\"\\n  âš ï¸ Restart candidates didn't improve fitness. Stopping.\")\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print(f\"\\nğŸ FINAL {dim}D COMPRESSION RESULTS ğŸ\")\n",
    "    print(f\"  Final position: {point}, Final fitness: {f:.6g}, Total steps: {len(traj)}\")\n",
    "    return traj\n",
    "\n",
    "def hill_climb_simple_nd(fitness_func_nd, start_point, dim, max_steps=2000):\n",
    "    point = tuple(int(x) for x in start_point)\n",
    "    f = fitness_func_nd(point)\n",
    "    traj = [(point, f)]\n",
    "    print(f\"\\nğŸš€ {dim}D BASELINE climb start at {point}, f={f:.4f}\\n\")\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        candidates = []\n",
    "        # 1. O(D)\n",
    "        for d in range(dim):\n",
    "            nm = list(point); nm[d] -= 1\n",
    "            np_ = list(point); np_[d] += 1\n",
    "            candidates.append((tuple(nm), fitness_func_nd(tuple(nm))))\n",
    "            candidates.append((tuple(np_), fitness_func_nd(tuple(np_))))\n",
    "        # 2. O(D^2) Diagonal\n",
    "        for d1, d2 in itertools.combinations(range(dim), 2):\n",
    "            for o1 in [1, -1]:\n",
    "                for o2 in [1, -1]:\n",
    "                    np_ = list(point); np_[d1] += o1; np_[d2] += o2\n",
    "                    candidates.append((tuple(np_), fitness_func_nd(tuple(np_))))\n",
    "\n",
    "        best_point, best_f = point, f\n",
    "        for cp, cf in candidates:\n",
    "            if cf < best_f - 1e-9: best_point, best_f = cp, cf\n",
    "        \n",
    "        if best_f < f - 1e-9:\n",
    "            point, f = best_point, best_f\n",
    "            traj.append((point, f))\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print(f\"ğŸ FINAL {dim}D BASELINE RESULTS ğŸ\")\n",
    "    print(f\"  Final position: {point}, Final fitness: {f:.6g}, Total steps: {len(traj)}\")\n",
    "    return traj\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. RANDOM FOREST HPO IMPLEMENTATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Global Data Cache for speed\n",
    "X_TRAIN, Y_TRAIN, X_VAL, Y_VAL = None, None, None, None\n",
    "\n",
    "def load_fashion_mnist_for_hpo(n_samples: int = 5000, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fashion MNISTë¥¼ ë¡œë“œí•˜ê³  Subsample ë° ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (ë°ì´í„° ê²€ì¦ ë¡œê¹… ì¶”ê°€)\n",
    "    \"\"\"\n",
    "    global X_TRAIN, Y_TRAIN, X_VAL, Y_VAL\n",
    "    \n",
    "    if X_TRAIN is not None:\n",
    "        return X_TRAIN, Y_TRAIN, X_VAL, Y_VAL\n",
    "\n",
    "    print(\"Loading Fashion MNIST (Subsample for increased difficulty)...\")\n",
    "    \n",
    "    try:\n",
    "        mnist = fetch_openml('Fashion-MNIST', version=1, cache=True, as_frame=False)\n",
    "        X, y = mnist.data, mnist.target\n",
    "        \n",
    "        # ğŸš¨ [ìˆ˜ì •ëœ ë¶€ë¶„]: íƒ€ê²Ÿ yë¥¼ np.int64ë¡œ ëª…í™•í•˜ê²Œ ë³€í™˜\n",
    "        X = X.astype(np.float64) \n",
    "        # y ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ (ë¬¸ìì—´ '0', '1' ë“±ë„ ì²˜ë¦¬ ê°€ëŠ¥)\n",
    "        y = y.astype(np.int64)\n",
    "        \n",
    "        # ğŸš¨ [ê²€ì¦ 1] ë¡œë“œ ì§í›„ ë°ì´í„° íƒ€ì… ë° í˜•íƒœ í™•ì¸\n",
    "        print(f\"  [CHECK 1: Raw Data] X Shape: {X.shape}, Y Type: {y.dtype}\")\n",
    "        print(f\"  [CHECK 1: Raw Data] X min/max: {X.min()}/{X.max()}\")\n",
    "\n",
    "        # ğŸš¨ [ìˆ˜ì • ë° ê²€ì¦ 2] ë°ì´í„° íƒ€ì… ëª…ì‹œì  ë³€í™˜\n",
    "        X = X.astype(np.float64) \n",
    "        y = y.astype(np.int64) \n",
    "\n",
    "        # Subsample ë° ë¶„í•  ë¡œì§\n",
    "        if n_samples > len(X): n_samples = len(X)\n",
    "            \n",
    "        X_sub, _, y_sub, _ = train_test_split(X, y, train_size=n_samples, random_state=random_state, stratify=y)\n",
    "        \n",
    "        X_train_sub, X_val_sub, Y_train_sub, Y_val_sub = train_test_split(\n",
    "            X_sub, y_sub, test_size=0.3, random_state=random_state, stratify=y_sub\n",
    "        )\n",
    "\n",
    "        # ğŸš¨ [ê²€ì¦ 3] ê²°ì¸¡ì¹˜ í™•ì¸ (ìŠ¤ì¼€ì¼ë§ ì „)\n",
    "        if np.isnan(X_train_sub).any() or np.isinf(X_train_sub).any():\n",
    "            print(\"  [CHECK 3: NaN/Inf Alert] Found NaN/Inf values before scaling.\")\n",
    "            \n",
    "        # ìŠ¤ì¼€ì¼ë§\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_sub)\n",
    "        X_val_scaled = scaler.transform(X_val_sub)\n",
    "        \n",
    "        # ğŸš¨ [ê²€ì¦ 4] ìŠ¤ì¼€ì¼ë§ í›„ ê°’ í™•ì¸ (í‰ê·  0, í‘œì¤€í¸ì°¨ 1 ê·¼ì²˜ì—¬ì•¼ í•¨)\n",
    "        print(f\"  [CHECK 4: Scaled Data] X_train mean/std: {np.mean(X_train_scaled):.4f} / {np.std(X_train_scaled):.4f}\")\n",
    "\n",
    "\n",
    "        X_TRAIN, Y_TRAIN = X_train_scaled, Y_train_sub\n",
    "        X_VAL, Y_VAL = X_val_scaled, Y_val_sub\n",
    "        \n",
    "        print(f\"Data Loaded: Train={len(X_TRAIN)} samples, Validation={len(X_VAL)} samples.\")\n",
    "        return X_TRAIN, Y_TRAIN, X_VAL, Y_VAL\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Fashion MNIST processing: {e}. Cannot proceed with HPO.\")\n",
    "        # HPO ì§„í–‰ ë¶ˆê°€ ì‹œ ì‹œìŠ¤í…œ ì¢…ë£Œ\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def rf_hpo_fitness_nd(point: Tuple[int, int, int]) -> float:\n",
    "    \"\"\"\n",
    "    Random Forest HPO ëª©í‘œ í•¨ìˆ˜: (n_estimators, max_depth, max_features_VALUE)ë¥¼ ì…ë ¥ë°›ì•„\n",
    "    Fitness (1 - Accuracy)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. íŒŒë¼ë¯¸í„° ë§¤í•‘ ë° ì œì•½ ì¡°ê±´ ì ìš©\n",
    "    n_estimators = max(50, min(200, int(point[0]))) # [50, 200]\n",
    "    max_depth = max(10, min(30, int(point[1])))     # [10, 30]\n",
    "    \n",
    "    # ğŸš¨ [ìˆ˜ì •ëœ ë¶€ë¶„]: x2ë¥¼ ì •ìˆ˜ê°’(50) ëŒ€ì‹  ë¹„ìœ¨(0.05 ~ 1.0)ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    # HPO frameworkëŠ” ì •ìˆ˜ 50ì„ ì „ë‹¬í•˜ì§€ë§Œ, ML ëª¨ë¸ì—ëŠ” 0.05ë¡œ ì „ë‹¬\n",
    "    # ì´ ë¹„ìœ¨ íŒŒë¼ë¯¸í„°ê°€ Local Optimaë¥¼ ìœ ë„í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.\n",
    "    # ì˜ˆ: point[2]=50 -> ratio=0.05 + 0.001*50 = 0.1\n",
    "    \n",
    "    # X_trainì„ ë¡œë“œí•˜ì—¬ ì‹¤ì œ íŠ¹ì§• ê°œìˆ˜(784)ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "    X_train, Y_train, X_val, Y_val = load_fashion_mnist_for_hpo()\n",
    "    \n",
    "    # x2ëŠ” ì´ì œ ë¹„ìœ¨(ratio)ì˜ ì •ìˆ˜ ì¸ë±ìŠ¤ì²˜ëŸ¼ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    # x2ì˜ íƒìƒ‰ ë²”ìœ„ [30, 70]ì„ [0.05, 0.75] ë¹„ìœ¨ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
    "    # 50ì€ ì¤‘ê°„ ì§€ì ì¸ 0.40ì— í•´ë‹¹ë˜ë„ë¡ ì„¤ê³„\n",
    "    feature_ratio_raw = int(point[2]) \n",
    "    \n",
    "    # (30 -> 0.05) to (70 -> 0.75) mapping\n",
    "    # Simple linear mapping: ratio = 0.05 + 0.01 * (x2 - 30)\n",
    "    # (100, 10, 50) ì‹œì‘ì  ê°€ì •: x2=50 -> ratio=0.05 + 0.01 * 20 = 0.25 \n",
    "    \n",
    "    # ratio_value = max(0.01, min(1.0, 0.05 + 0.01 * (feature_ratio_raw - 30))) # 30ì—ì„œ ì‹œì‘í–ˆë‹¤ê³  ê°€ì •í•˜ê³  ì¡°ì •\n",
    "    \n",
    "    # HPOê°€ 1ë¶€í„° 200ê¹Œì§€ ì •ìˆ˜ë¥¼ íƒìƒ‰í•˜ë¯€ë¡œ, x2 ê°’ì„ 1~200ìœ¼ë¡œ ë³´ê³  0.05~1.0 ë¹„ìœ¨ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
    "    # Start Point 50 -> 0.25 (ì ì ˆí•œ ê°’)\n",
    "    max_features_ratio = max(0.05, min(1.0, feature_ratio_raw / 200.0))\n",
    "    \n",
    "    # 2. Model Training & Evaluation\n",
    "    try:\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=max_depth,\n",
    "            max_features=max_features_ratio, # ğŸš¨ float ë¹„ìœ¨ì„ ì „ë‹¬\n",
    "            random_state=42, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        fitness = 1.0 - accuracy\n",
    "        \n",
    "    except Exception as e:\n",
    "        fitness = 1.0 \n",
    "\n",
    "    return fitness\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MAIN EXECUTION (START POINT ë° HPO ì„¤ì • ì¡°ì •)\n",
    "# ==============================================================================\n",
    "# D=3 ì°¨ì›ì„ ê³ ë ¤í•˜ì—¬ START_POINTì˜ x2 ê°’ì„ 1~200 ë²”ìœ„ ë‚´ì—ì„œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "DIM = 3 \n",
    "START_POINT_HPO = (50, 15, 50) # N=50, D=15, F_ratio=50/200=0.25 (ì•ˆì „í•œ ì„±ëŠ¥ ë³´ì¥)\n",
    "THRESHOLD = 0.00001\n",
    "MAX_ITERATIONS = 10 \n",
    "BASIN_MAX_SEARCH = 50\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ Random Forest HPO Comparison (D=3) - í•™ìŠµ ëŠ¥ë ¥ ë³µì›\")\n",
    "print(f\"   Parameters: (n_estimators, max_depth, max_features)\")\n",
    "print(f\"   Start Point: {START_POINT_HPO}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- 1. Run with Compression HC ---\n",
    "time_start_comp = time.time()\n",
    "traj_comp = hill_climb_with_compression_nd(\n",
    "    fitness_func_nd=rf_hpo_fitness_nd,\n",
    "    start_point=START_POINT_HPO,\n",
    "    dim=DIM,\n",
    "    max_iterations=10, # Iteration íšŸìˆ˜ 5 -> 10ìœ¼ë¡œ ëŠ˜ë ¤ Compression ê¸°íšŒ ë¶€ì—¬\n",
    "    basin_max_search=20,\n",
    "    global_min_threshold=THRESHOLD\n",
    ")\n",
    "time_end_comp = time.time()\n",
    "\n",
    "# --- 2. Run Baseline HC ---\n",
    "time_start_base = time.time()\n",
    "traj_baseline = hill_climb_simple_nd(\n",
    "    fitness_func_nd=rf_hpo_fitness_nd,\n",
    "    start_point=START_POINT_HPO,\n",
    "    dim=DIM,\n",
    "    max_steps=500\n",
    ")\n",
    "time_end_base = time.time()\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. FINAL SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "def print_final_summary(traj, time_taken, label):\n",
    "    if not traj:\n",
    "        print(f\" Â {label:<30}: FAILED (No steps)\")\n",
    "        return 0.0\n",
    "    \n",
    "    final_f = traj[-1][1]\n",
    "    final_p = traj[-1][0]\n",
    "    accuracy = 1.0 - final_f\n",
    "    steps = len(traj)\n",
    "    \n",
    "    print(f\" Â {label:<30}:\")\n",
    "    print(f\" Â  Â - Final Params (N, D): {str(final_p):<25}\")\n",
    "    print(f\" Â  Â - Final Fitness (Min): {final_f:<25.6f}\")\n",
    "    print(f\" Â  Â - Final Accuracy: Â  Â  Â {accuracy:<25.6f}\")\n",
    "    print(f\" Â  Â - Total Steps: Â  Â  Â  Â  {steps:<25}\")\n",
    "    print(f\" Â  Â - Time Taken (s): Â  Â  Â {time_taken:<25.4f}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "print(\"\\n\" + \"==\"*40)\n",
    "print(\" Â  Â  Â  Â FINAL RANDOM FOREST HPO COMPARISON\")\n",
    "print(\"==\"*40)\n",
    "\n",
    "acc_comp = print_final_summary(traj_comp, time_end_comp - time_start_comp, \"Compression Hill Climbing\")\n",
    "acc_base = print_final_summary(traj_baseline, time_end_base - time_start_base, \"Baseline Hill Climbing\")\n",
    "\n",
    "print(\"\\n--- HPO Efficacy ---\")\n",
    "if acc_comp > acc_base + 1e-4:\n",
    "    print(f\"ğŸ‰ **Compression HC Succeeded!** (Accuracy improvement: {acc_comp - acc_base:.4f})\")\n",
    "else:\n",
    "    print(\"âš ï¸ Baseline and Compression HC performed similarly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
